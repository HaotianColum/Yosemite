{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AccessiTrip AI: Smart Accessible Travel Planner\n",
    "\n",
    "A 2-hour MVP demo leveraging Databricks, Unity Catalog, Mosaic AI, Delta, RAG, agent tools, MLflow, and Streamlit.  \n",
    "**Purpose:** Help travelers (with or without accessibility needs) find accessible places to stay and visit in any US city, using Bright Initiative datasets (Airbnb, Booking.com, Google Maps Businesses).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Access: Delta Tables & Demo Data\n",
    "\n",
    "This notebook can use either real Delta tables (from Unity Catalog) or in-memory demo data. Toggle the `USE_DEMO_DATA` flag below.\n",
    "\n",
    "- **Delta Table Mode:** Reads from Unity Catalog tables (Airbnb, Booking.com, Google Maps Businesses). See `partner_data_quickstart.ipynb` and `nimble-mcp.ipynb` for patterns.\n",
    "- **Demo Mode:** Uses small in-memory DataFrames for fast prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggle this to False to use real Delta tables\n",
    "USE_DEMO_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RAG: Databricks Vector Search Integration\n",
    "\n",
    "This section demonstrates how to use Databricks Vector Search for retrieval-augmented generation (RAG) over your Delta tables. (See also: vector_search_fm_api.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "# Set up vector search client and index names\n",
    "CATALOG = \"main\"\n",
    "DB = \"bright_airbnb\"\n",
    "SOURCE_TABLE_NAME = \"listings\"\n",
    "SOURCE_TABLE_FULLNAME = f\"{CATALOG}.{DB}.{SOURCE_TABLE_NAME}\"\n",
    "VS_ENDPOINT_NAME = \"vs_endpoint\"\n",
    "VS_INDEX_NAME = \"accessitrip_vs_index\"\n",
    "VS_INDEX_FULLNAME = f\"{CATALOG}.{DB}.{VS_INDEX_NAME}\"\n",
    "\n",
    "vsc = VectorSearchClient()\n",
    "\n",
    "# Ensure endpoint exists\n",
    "if vsc.list_endpoints().get('endpoints') is None or not VS_ENDPOINT_NAME in [e.get('name') for e in vsc.list_endpoints().get('endpoints')]:\n",
    "    vsc.create_endpoint(VS_ENDPOINT_NAME)\n",
    "vsc.wait_for_endpoint(VS_ENDPOINT_NAME, 600)\n",
    "\n",
    "# Ensure index exists\n",
    "if not VS_INDEX_FULLNAME in [i.get(\"name\") for i in vsc.list_indexes(VS_ENDPOINT_NAME).get('vector_indexes', [])]:\n",
    "    vsc.create_delta_sync_index_and_wait(\n",
    "        endpoint_name=VS_ENDPOINT_NAME,\n",
    "        index_name=VS_INDEX_FULLNAME,\n",
    "        source_table_name=SOURCE_TABLE_FULLNAME,\n",
    "        pipeline_type=\"TRIGGERED\",\n",
    "        primary_key=\"id\",\n",
    "        embedding_source_column=\"description\",\n",
    "        embedding_model_endpoint_name=\"databricks-bge-large-en\"\n",
    "    )\n",
    "\n",
    "index = vsc.get_index(endpoint_name=VS_ENDPOINT_NAME, index_name=VS_INDEX_FULLNAME)\n",
    "\n",
    "# Example RAG query\n",
    "rag_results = index.similarity_search(\n",
    "    columns=[\"name\", \"description\", \"amenities\"],\n",
    "    query_text=\"wheelchair accessible hotel in Chicago\",\n",
    "    num_results=3\n",
    ")\n",
    "\n",
    "# Convert results to DataFrame for downstream use\n",
    "import pandas as pd\n",
    "if rag_results and rag_results.get('result') and rag_results['result'].get('data_array'):\n",
    "    rag_df = pd.DataFrame(rag_results['result']['data_array'], columns=[\"name\", \"description\", \"amenities\"])\n",
    "else:\n",
    "    rag_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modular Agent Tools: SQL, RAG, LLM, Logging\n",
    "\n",
    "This section defines agent tools for:\n",
    "- Lodging/business search (SQL or RAG)\n",
    "- Accessibility review summarization (LLM)\n",
    "- Message drafting (LLM)\n",
    "- MLflow logging\n",
    "\n",
    "The agent can use either SQL (Delta tables), RAG (vector search), or demo data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_databricks import ChatDatabricks\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import os\n",
    "\n",
    "w = WorkspaceClient()\n",
    "os.environ[\"DATABRICKS_HOST\"] = w.config.host\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = w.tokens.create(comment=\"for model serving\", lifetime_seconds=1200).token_value\n",
    "llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=1024)\n",
    "mlflow.langchain.autolog()\n",
    "\n",
    "def find_accessible_lodging(city, need=None, top_n=3, use_rag=False):\n",
    "    if use_rag:\n",
    "        # Use RAG/vector search\n",
    "        query = f\"{need or ''} hotel in {city}\"\n",
    "        rag_results = index.similarity_search(\n",
    "            columns=[\"name\", \"description\", \"amenities\"],\n",
    "            query_text=query,\n",
    "            num_results=top_n\n",
    "        )\n",
    "        if rag_results and rag_results.get('result') and rag_results['result'].get('data_array'):\n",
    "            df = pd.DataFrame(rag_results['result']['data_array'], columns=[\"name\", \"description\", \"amenities\"])\n",
    "            df[\"price\"] = None  # Add price if available in your index\n",
    "            df[\"reviews\"] = \"[]\"  # Add reviews if available\n",
    "            return df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        # Use demo or SQL data\n",
    "        df = lodging_df[lodging_df[\"location\"].str.contains(city, case=False)]\n",
    "        if need:\n",
    "            mask = (\n",
    "                df[\"amenities\"].str.contains(need, case=False, na=False) |\n",
    "                df[\"description\"].str.contains(need, case=False, na=False) |\n",
    "                df[\"reviews\"].apply(lambda reviews: any(need.lower() in r.lower() for r in reviews))\n",
    "            )\n",
    "            df = df[mask]\n",
    "        return df.head(top_n)\n",
    "\n",
    "def summarize_reviews_llm(reviews, need=None):\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        You are an expert travel assistant. Summarize the following user reviews for accessibility features{need_clause}.\n",
    "        Reviews:\n",
    "        {reviews}\n",
    "        \"\"\".strip()\n",
    "    )\n",
    "    need_clause = f\" (focus on '{need}')\" if need else \"\"\n",
    "    context = {\"reviews\": \"\\n\".join(reviews), \"need_clause\": need_clause}\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    return chain.invoke(context)\n",
    "\n",
    "def find_accessible_businesses(city, need=None, top_n=2):\n",
    "    df = business_df[business_df[\"location\"].str.contains(city, case=False)]\n",
    "    if need:\n",
    "        mask = (\n",
    "            df[\"accessibility\"].str.contains(need, case=False, na=False) |\n",
    "            df[\"reviews\"].apply(lambda reviews: any(need.lower() in r.lower() for r in reviews))\n",
    "        )\n",
    "        df = df[mask]\n",
    "    return df.sort_values(\"rating\", ascending=False).head(top_n)\n",
    "\n",
    "def draft_inquiry_message(place_name, need):\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        Draft a polite message to {place_name} asking to confirm if they have {need} available for guests.\n",
    "        \"\"\".strip()\n",
    "    )\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    return chain.invoke({\"place_name\": place_name, \"need\": need})\n",
    "\n",
    "def log_agent_action(user_query, params, results):\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_text(str(results), \"results.txt\")\n",
    "    mlflow.log_text(user_query, \"user_query.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streamlit UI: Unified Experience\n",
    "\n",
    "A simple UI for city/needs input, results display, and agent Q&A. Toggle between RAG and SQL/demo search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.set_page_config(page_title=\"AccessiTrip AI\", layout=\"wide\")\n",
    "st.title(\"AccessiTrip AI: Smart Accessible Travel Planner\")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"Plan Your Accessible Trip\")\n",
    "    city = st.text_input(\"Where are you traveling?\", value=\"Chicago\")\n",
    "    need = st.text_input(\"Any accessibility or preference needs? (e.g. wheelchair, pet, quiet)\", value=\"wheelchair\")\n",
    "    use_rag = st.checkbox(\"Use RAG/Vector Search\", value=False)\n",
    "    if st.button(\"Search\"):\n",
    "        st.session_state[\"search\"] = True\n",
    "\n",
    "if st.session_state.get(\"search\"):\n",
    "    # Lodging results\n",
    "    st.subheader(\"Accessible Stays\")\n",
    "    stays = find_accessible_lodging(city, need, use_rag=use_rag)\n",
    "    for _, row in stays.iterrows():\n",
    "        st.markdown(f\"**{row.get('name','')}** ‚Äî ${row.get('price','N/A')} per night\")\n",
    "        st.markdown(f\"*Amenities*: {row.get('amenities','')}\")\n",
    "        summary = summarize_reviews_llm(row.get(\"reviews\", []), need) if row.get(\"reviews\") else \"\"\n",
    "        st.markdown(f\"*Why we suggest this*: {summary}\")\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "    # Businesses\n",
    "    st.subheader(\"Nearby Accessible Restaurants/Attractions\")\n",
    "    businesses = find_accessible_businesses(city, need)\n",
    "    for _, row in businesses.iterrows():\n",
    "        st.markdown(f\"**{row['name']}** ({row['type']}, {row['rating']}‚≠ê)\")\n",
    "        st.markdown(f\"*Accessibility*: {row['accessibility']}\")\n",
    "        summary = summarize_reviews_llm(row[\"reviews\"], need)\n",
    "        st.markdown(f\"*Review summary*: {summary}\")\n",
    "        st.markdown(\"---\")\n",
    "\n",
    "    # Suggested inquiry message\n",
    "    st.subheader(\"Copy Suggested Inquiry Email/Message\")\n",
    "    if not stays.empty:\n",
    "        msg = draft_inquiry_message(stays.iloc[0][\"name\"], need)\n",
    "        st.code(msg, language=\"text\")\n",
    "\n",
    "    # Log actions\n",
    "    log_agent_action(\n",
    "        user_query=f\"city={city}, need={need}, use_rag={use_rag}\",\n",
    "        params={\"city\": city, \"need\": need, \"use_rag\": use_rag},\n",
    "        results={\"stays\": stays.to_dict(), \"businesses\": businesses.to_dict()}\n",
    "    )\n",
    "\n",
    "    # Agent Q&A\n",
    "    st.subheader(\"Not sure? Ask the Agent!\")\n",
    "    user_q = st.text_input(\"Ask a specific question (e.g. 'Is there an accessible bathroom?')\")\n",
    "    if st.button(\"Ask Agent\"):\n",
    "        all_reviews = []\n",
    "        for _, row in stays.iterrows():\n",
    "            if row.get(\"reviews\"):\n",
    "                all_reviews.extend(row[\"reviews\"])\n",
    "        answer = summarize_reviews_llm(all_reviews, user_q)\n",
    "        st.markdown(f\"**Agent:** {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Extensibility\n",
    "\n",
    "- Each section is a modular agent tool/function.\n",
    "- Swap in real Delta/Unity tables for production.\n",
    "- Add more datasets (insurance, maps, etc.) as needed.\n",
    "- MLflow logs all actions for traceability.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Demo Output Example\n",
    "\n",
    "> **Top Accessible Hotels:**  \n",
    "> - [The Grand Loop Hotel]: ‚ÄúStep-free entrance, elevator, user review: ‚ÄòRamps are well maintained.‚Äô‚Äù  \n",
    "> - [Wabash Suites]: ‚ÄúRoll-in shower, wide hallways, recent guest: ‚ÄòNo stairs, great for my wheelchair!‚Äô‚Äù  \n",
    ">\n",
    "> **Nearby Accessible Restaurants:**  \n",
    "> - [Fresh & Easy Diner]: ‚ÄúNo steps, accessible bathroom, all employees are trained.‚Äù  \n",
    "> - [Lakeside Grill]: ‚ÄúAccessible by public transit, quiet, braille menus.‚Äù\n",
    ">\n",
    "> **Suggested message to hotel:**  \n",
    "> - ‚ÄúHello, can you confirm your entrance and elevator accommodate wheelchairs? Are there accessible bathrooms in the guest rooms?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to demo, extend, and impress!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Code Assistant: In-Notebook and Streamlit Chat\n",
    "\n",
    "This section enables a code assistant using Databricks LLMs. You can ask coding/data questions and get answers or code suggestions directly in the notebook or via the Streamlit UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_databricks import ChatDatabricks\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import streamlit as st\n",
    "\n",
    "# Instantiate a chat LLM for code assistance\n",
    "code_llm = ChatDatabricks(endpoint=\"databricks-llama-4-maverick\", max_tokens=1024)\n",
    "\n",
    "# Define a prompt template for code Q&A\n",
    "code_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a helpful Databricks code assistant. Answer the user's coding or data question. If code is needed, provide a concise, working code snippet for Databricks (PySpark, SQL, or Python as appropriate). If the question is about data access, reference Unity Catalog/Delta best practices. If the question is about RAG or agents, reference Databricks Vector Search and LangChain integration.\n",
    "    \n",
    "    User question: {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "code_chain = code_prompt | code_llm | StrOutputParser()\n",
    "\n",
    "def code_assistant_ask(question):\n",
    "    \"\"\"Ask the code assistant a question and get an answer/code snippet.\"\"\"\n",
    "    return code_chain.invoke({\"question\": question})\n",
    "\n",
    "# Streamlit UI for code assistant\n",
    "if 'code_chat_history' not in st.session_state:\n",
    "    st.session_state['code_chat_history'] = []\n",
    "\n",
    "with st.expander(\"üí¨ Code Assistant Chat (Databricks)\"):\n",
    "    st.markdown(\"Ask any Databricks coding/data question. Get code or best practices instantly!\")\n",
    "    code_user_q = st.text_input(\"Your coding/data question\", key=\"code_assistant_input\")\n",
    "    if st.button(\"Ask Code Assistant\"):\n",
    "        if code_user_q:\n",
    "            code_answer = code_assistant_ask(code_user_q)\n",
    "            st.session_state['code_chat_history'].append((code_user_q, code_answer))\n",
    "    for q, a in st.session_state['code_chat_history']:\n",
    "        st.markdown(f\"**You:** {q}\")\n",
    "        st.markdown(f\"**Assistant:** {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "- In notebook: Call `code_assistant_ask(\"your question\")` in a code cell to get a code/data answer.\n",
    "- In Streamlit: Use the \"Code Assistant Chat\" expander to ask questions and see answers interactively.\n",
    "- Example: `code_assistant_ask(\"How do I join two Delta tables in PySpark?\")`\n",
    "- The assistant will return a concise answer or code snippet, referencing Databricks best practices."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "vector_search_fm_api",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
